# ML Practice: Arm Distribution or Actions
Practicing Machine Learning by creating a distribution reward matrix with normally distributed rewards with a small variance that is ideal with normal distribution rewards and simulating the data using R language.

## Creating the Matrix Being Used
Instead of finding a dataset to use, I am creating my own matrix that starts with 3, increasing the number by 1.5 until we have 10 numbers. After, I created the reward distribution before preparing my data simulation. See screenshot.

![Screenshot of arm distribution or actions with normally distributed rewards with small variance.](https://github.com/CrawleyM29/ML_Practice/blob/data-engineering/Arm%20Distribution%20ML/Beginning%20Code.JPG)

I then viewed my dataset to make sure it was clean and correct for my simulation. I only took a screenshot of the first 13 rows, it does have 10,000 lines with various outcomes.

![View of dataset](https://github.com/CrawleyM29/ML_Practice/blob/data-engineering/Arm%20Distribution%20ML/Dataset%20View.JPG)

## Creating Dataset with Arm and Reward Combination 

After creating the dataset and making sure it was clean and created it, I assigned column names from V1 - V10 to 1-10. In my first dataset picture, you don't see V1 to V10 as I completed my project prior to putting it up on GitHub. 

![Assigning column names and creating a reward combiniation](https://github.com/CrawleyM29/ML_Practice/blob/data-engineering/Arm%20Distribution%20ML/data%20prep.JPG)

### Plot-I Code and Visual

The following is the plot for the distributions of rewards from Bandits

![Code for Plot I](https://github.com/CrawleyM29/ML_Practice/blob/data-engineering/Arm%20Distribution%20ML/Plot1.JPG)



